import SeleneShared
import XCTest
import Foundation
@testable import SeleneChat

/// Integration tests for the conversation memory system
/// These tests require Ollama to be running at localhost:11434
final class MemoryIntegrationTests: XCTestCase {
    var databaseService: DatabaseService!
    var testDatabasePath: String!

    override func setUp() async throws {
        try await super.setUp()

        // Create a temporary database for testing
        let tempDir = FileManager.default.temporaryDirectory
        testDatabasePath = tempDir.appendingPathComponent("test_memory_integration_\(UUID().uuidString).db").path

        // Initialize database service with test path
        databaseService = DatabaseService()
        databaseService.databasePath = testDatabasePath
    }

    override func tearDown() async throws {
        // Clean up test database
        try? FileManager.default.removeItem(atPath: testDatabasePath)
        databaseService = nil
        try await super.tearDown()
    }

    // MARK: - Ollama Integration Tests

    /// Test that OllamaService can generate embeddings
    func testOllamaEmbedding() async throws {
        let ollamaService = OllamaService.shared

        // Check if Ollama is available
        let isAvailable = await ollamaService.isAvailable()
        try XCTSkipUnless(isAvailable, "Ollama not running - skipping integration test")

        // Generate embedding for test text
        let embedding = try await ollamaService.embed(text: "User prefers dark mode interfaces")

        XCTAssertFalse(embedding.isEmpty, "Embedding should not be empty")
        XCTAssertEqual(embedding.count, 768, "nomic-embed-text produces 768-dimension embeddings")
    }

    /// Test that OllamaService can generate text (needed for memory extraction)
    func testOllamaGenerate() async throws {
        let ollamaService = OllamaService.shared

        // Check if Ollama is available
        let isAvailable = await ollamaService.isAvailable()
        try XCTSkipUnless(isAvailable, "Ollama not running - skipping integration test")

        // Simple generation test
        let response = try await ollamaService.generate(prompt: "Say 'hello' and nothing else.")

        XCTAssertFalse(response.isEmpty, "Response should not be empty")
        XCTAssertTrue(response.lowercased().contains("hello"), "Response should contain 'hello'")
    }

    /// Test the full memory extraction flow with real Ollama
    func testMemoryExtractionWithOllama() async throws {
        let ollamaService = OllamaService.shared
        let memoryService = MemoryService.shared

        // Check if Ollama is available
        let isAvailable = await ollamaService.isAvailable()
        try XCTSkipUnless(isAvailable, "Ollama not running - skipping integration test")

        // Simulate a conversation exchange
        let userMessage = "I'm working on a Swift project called Selene for ADHD note management"
        let assistantResponse = "That's a great project! Selene sounds like it will help people with ADHD organize their thoughts and notes more effectively."

        // Recent messages context (empty for this test)
        let recentMessages: [(role: String, content: String, createdAt: Date)] = []

        // Extract memories
        let facts = try await memoryService.extractMemories(
            userMessage: userMessage,
            assistantResponse: assistantResponse,
            recentMessages: recentMessages
        )

        // The LLM should extract at least one fact about the user working on Selene
        print("Extracted \(facts.count) facts:")
        for fact in facts {
            print("  - [\(fact.type)] \(fact.fact) (confidence: \(fact.confidence))")
        }

        // We expect at least one fact to be extracted
        // Note: LLM output can vary, so we're lenient here
        XCTAssertGreaterThanOrEqual(facts.count, 0, "Should extract facts (may be 0 if LLM is conservative)")

        // If facts were extracted, verify structure
        for fact in facts {
            XCTAssertFalse(fact.fact.isEmpty, "Fact content should not be empty")
            // LLM may return types outside our schema - just log them
            let validTypes = ["preference", "fact", "pattern", "context"]
            if !validTypes.contains(fact.type) {
                print("  Note: LLM returned non-standard type '\(fact.type)' - will default to 'fact'")
            }
            XCTAssertGreaterThan(fact.confidence, 0, "Confidence should be positive")
            XCTAssertLessThanOrEqual(fact.confidence, 1, "Confidence should be <= 1")
        }
    }

    /// Test full flow: conversation -> extraction -> storage -> retrieval
    func testEndToEndMemoryFlow() async throws {
        let ollamaService = OllamaService.shared
        let memoryService = MemoryService.shared

        // Check if Ollama is available
        let isAvailable = await ollamaService.isAvailable()
        try XCTSkipUnless(isAvailable, "Ollama not running - skipping integration test")

        let sessionId = UUID()

        // 1. Save conversation to database
        try await databaseService.saveConversationMessage(
            sessionId: sessionId,
            role: "user",
            content: "I prefer to code in the morning when I have more focus"
        )
        try await databaseService.saveConversationMessage(
            sessionId: sessionId,
            role: "assistant",
            content: "Morning coding sessions are great for deep work! Your brain is often freshest then."
        )

        // 2. Verify conversation was saved
        let messages = try await databaseService.getRecentMessages(sessionId: sessionId, limit: 10)
        XCTAssertEqual(messages.count, 2, "Should have 2 messages saved")

        // 3. Extract memories from the exchange
        let facts = try await memoryService.extractMemories(
            userMessage: "I prefer to code in the morning when I have more focus",
            assistantResponse: "Morning coding sessions are great for deep work! Your brain is often freshest then.",
            recentMessages: []
        )

        print("Extracted facts: \(facts.count)")

        // 4. Store any extracted memories
        for fact in facts {
            let memoryId = try await databaseService.insertMemory(
                content: fact.fact,
                type: ConversationMemory.MemoryType(rawValue: fact.type) ?? .fact,
                confidence: fact.confidence,
                sourceSessionId: sessionId
            )
            print("Stored memory #\(memoryId): \(fact.fact)")
        }

        // 5. Verify memories in database
        let storedMemories = try await databaseService.getAllMemories(limit: 10)
        XCTAssertEqual(storedMemories.count, facts.count, "Stored memory count should match extracted facts")

        // 6. Test retrieval (keyword-based for MVP)
        let relevantMemories = try await memoryService.getRelevantMemories(for: "morning coding", limit: 5)
        print("Retrieved \(relevantMemories.count) relevant memories for 'morning coding'")

        // Success! Full flow completed
        print("âœ… End-to-end memory flow completed successfully")
    }

    /// Test memory consolidation logic
    /// Note: This test uses the shared MemoryService which uses shared DatabaseService
    /// So we test the consolidation decision logic without database interaction
    func testMemoryConsolidation() async throws {
        let ollamaService = OllamaService.shared

        // Check if Ollama is available
        let isAvailable = await ollamaService.isAvailable()
        try XCTSkipUnless(isAvailable, "Ollama not running - skipping integration test")

        // Test the consolidation prompt by asking the LLM directly
        let prompt = """
        You are managing a memory system. Given a new fact and existing similar
        memories, decide what to do.

        NEW FACT: "User drinks strong coffee in the morning"

        EXISTING SIMILAR MEMORIES:
        1. [id=1] User likes coffee

        Return ONLY valid JSON matching one of these formats (no other text):
        - {"action": "ADD"} - New information, nothing equivalent exists
        - {"action": "UPDATE", "memoryId": N, "merged": "combined fact text"} - Augment existing
        - {"action": "DELETE", "memoryId": N, "reason": "why"} - New fact contradicts this
        - {"action": "NOOP", "reason": "why"} - Already known or not worth storing

        Consider: Is this genuinely new? Does it contradict something? Is it worth remembering?
        """

        let response = try await ollamaService.generate(prompt: prompt)
        print("Consolidation response: \(response)")

        // The LLM should return a valid JSON decision
        XCTAssertTrue(response.contains("{"), "Response should contain JSON")
        XCTAssertTrue(
            response.contains("ADD") || response.contains("UPDATE") ||
            response.contains("DELETE") || response.contains("NOOP"),
            "Response should contain a valid action"
        )
    }
}
